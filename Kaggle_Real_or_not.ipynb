{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kaggle Real or not",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyMtbjWdJzfLHMBQbfylSfsT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Suryanarayanang98/Kaggle--Real-or-Not-NLP-with-Disaster/blob/master/Kaggle_Real_or_not.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGmvFx6Dl2hV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "!pip install ktrain"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvIlOY8AdBxZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r kaggle\n",
        "!git clone https://github.com/Suryanarayanang98/Kaggle--Real-or-Not-NLP-with-Disaster.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEHsSnI5me5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainurl='https://raw.githubusercontent.com/Suryanarayanang98/Kaggle--Real-or-Not-NLP-with-Disaster/master/train.csv'\n",
        "train=pd.read_csv(trainurl)\n",
        "testurl='https://raw.githubusercontent.com/Suryanarayanang98/Kaggle--Real-or-Not-NLP-with-Disaster/master/test.csv'\n",
        "test=pd.read_csv(testurl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRSfyAngnKui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX3PoRTknMpL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5aMgpztnOy9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train[train['target']==1]['id'][:40]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHaQTi9YncXV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train[train['target']==0]['id'][:40]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oIkGsdonfzw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xH9ZZotun_rh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install --quiet tensorflow-hub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uthBi4TbD6sP",
        "colab_type": "text"
      },
      "source": [
        "Checking for Null values\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X82Scr3os7N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.heatmap(train.isnull()).set(title = 'Missing Data', xlabel = 'Columns', ylabel = 'Data Points')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHARwBttpBbA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.heatmap(test.isnull()).set(title = 'Missing Data', xlabel = 'Columns', ylabel = 'Data Points')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsPLdIEiEBk9",
        "colab_type": "text"
      },
      "source": [
        "Dropping Location"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIgkPDi4pIGQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Seperation based on id column for test and train\n",
        "test.drop(['location'],1,inplace=True)\n",
        "train.drop(['location'],1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrKKjStWrLaE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train\n",
        "#0-44 -Category 1\n",
        "#10835-inf -Category 2\n",
        "\n",
        "# test\n",
        "#0-45 - Category 1\n",
        "#10836-inf - Category 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22cABeIVEG3y",
        "colab_type": "text"
      },
      "source": [
        "Assigning id manually for few missing values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qETjLsq9scKB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(31):\n",
        "  train['keyword'][i]='Category 1'\n",
        "for j in range(15):\n",
        "  test['keyword'][i]='Category 1'\n",
        "train['keyword'].fillna('Category new',inplace=True)\n",
        "test['keyword'].fillna('Category new',inplace=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upWHPShWENYK",
        "colab_type": "text"
      },
      "source": [
        "Checking null values again"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEcaK24Cshwi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.heatmap(train.isnull()).set(title = 'Missing Data', xlabel = 'Columns', ylabel = 'Data Points')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ej-MVBmItwuV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.heatmap(test.isnull()).set(title = 'Missing Data', xlabel = 'Columns', ylabel = 'Data Points')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOoDHXIyERXB",
        "colab_type": "text"
      },
      "source": [
        "Uniques keyword"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ft6kTcD1t_L6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['keyword'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tz6XeNilEUbR",
        "colab_type": "text"
      },
      "source": [
        "Code for cleaning keyword names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocrfqz-WuHyx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %20 remove\n",
        "# bioterror,bioterrorism\n",
        "# electrocute,electrocuted\n",
        "# explode,exploded,explosion\n",
        "# forest%20fire,forest%20fires\n",
        "# flood,flooding,floods\n",
        "import re\n",
        "#text=re.sub('%20',' ',train['keyword'])\n",
        "train['keyword'].replace('%20',' ')\n",
        "def remove_punctuation(text):    \n",
        "    punctuations = '¯™¥-♥#$%&:;\\()+-<=>@[\\\\]^_`{|}~/¯( ͡° ͜ʖ ͡°) ͜ʖ° ͜ʖ ͡°ʖ ͡☉ ͡☉ ͡ ͡ ͡  ͡ ▌░╔╗║╔═╗20'\n",
        "    for p in punctuations:\n",
        "        text = text.replace(p, ' ')\n",
        "    text = re.sub(' +', ' ', text)\n",
        "    return text\n",
        "        \n",
        "train['keyword'] = train['keyword'].apply(lambda x: remove_punctuation(x)) \n",
        "test['keyword'] = test['keyword'].apply(lambda x: remove_punctuation(x))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZGPJr3CyCPd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['keyword'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDgXM3MbyMXT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test['keyword'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2J4GUU6jEekN",
        "colab_type": "text"
      },
      "source": [
        "TEXT CLEANING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a09u2xIfyi1f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text='SOOOO PUMPED FOR ABLAZE ???? @southridgelife'\n",
        "# Removing mentions\n",
        "def username(text):\n",
        "  text=re.sub('@[^\\s]+','',text)\n",
        "  return text\n",
        "import string\n",
        "\n",
        "# Removing URLs\n",
        "def remove_URL(text):\n",
        "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    return url.sub(r'',text)\n",
        "\n",
        "# Remove Punctuations\n",
        "def remove_punct(text):\n",
        "    table=str.maketrans('','',string.punctuation)\n",
        "    return text.translate(table)\n",
        "\n",
        "# Removing HTML\n",
        "def remove_html(text):\n",
        "    html=re.compile(r'<.*?>')\n",
        "    return html.sub(r'',text)\n",
        "\n",
        "train['text']=train['text'].apply(lambda x : remove_URL(x))\n",
        "test['text']=test['text'].apply(lambda x : remove_URL(x))\n",
        "\n",
        "train['text']=train['text'].apply(lambda x : remove_html(x))\n",
        "test['text']=test['text'].apply(lambda x : remove_html(x))\n",
        "\n",
        "train['text']=train['text'].apply(lambda x : username(x))\n",
        "test['text']=test['text'].apply(lambda x : username(x))\n",
        "\n",
        "train['text']=train['text'].apply(lambda x : remove_punct(x))\n",
        "test['text']=test['text'].apply(lambda x : remove_punct(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZWx5axI0A07",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.head(4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rj-SkblL0hnR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['keyword'][0]='earthquake'\n",
        "train['keyword'][1]='forest fire'\n",
        "train['keyword'][3]='forest fire'\n",
        "train['keyword'][4]='forest fire'\n",
        "train['keyword'][5]='forest fire'\n",
        "train['keyword'][6]='flood'\n",
        "train['keyword'][12]='flood'\n",
        "train['keyword'][11]='flood'\n",
        "train['keyword'][13]='flood'\n",
        "train['keyword'][14]='crash'\n",
        "\n",
        "\n",
        "train['keyword'][7]='forest fire'\n",
        "for i in range(15,31):\n",
        "  train['keyword'][i]='Category 3'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61uGtAzT4zAp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.head(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSDEB5WR41FA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test['keyword'][0]='crash'\n",
        "test['keyword'][1]='earthquake'\n",
        "test['keyword'][2]='forest fire'\n",
        "test['keyword'][3]='forest fire'\n",
        "test['keyword'][4]='Category 1'\n",
        "test['keyword'][5]='earthquake'\n",
        "test['keyword'][6]='Category 1'\n",
        "for i in range(7,15):\n",
        "  test['keyword'][i]='Category 3'\n",
        "\n",
        "test.head(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TSKqwLS5YaT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test.head(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEZOGY_sE3Fk",
        "colab_type": "text"
      },
      "source": [
        "Import Spacy for cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUAsOa3hB0Iu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy \n",
        "from spacy.lang.en.stop_words import STOP_WORDS as stopwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqUdNM0iE9mt",
        "colab_type": "text"
      },
      "source": [
        "Number of words in a tweet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h55vbTOyCnCW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['wordcount']=train['text'].apply(lambda x: len(str(x).split()))\n",
        "test['wordcount']=test['text'].apply(lambda x: len(str(x).split()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jb85AvxJC2Eg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Maximum and minimum number of words in tweets\n",
        "train['wordcount'].max(),train['wordcount'].min()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3DPlNpXDNje",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train[train['wordcount']==1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ssli04pFKaR",
        "colab_type": "text"
      },
      "source": [
        "Character Count"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqACgRRyDnuG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def char_count(x):\n",
        "  s=x.split()\n",
        "  x=''.join(s)\n",
        "  return len(x)\n",
        "train['charcount']=train['text'].apply(lambda x : char_count(str(x)))\n",
        "test['charcount']=test['text'].apply(lambda x : char_count(str(x)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuuHhlsREYL8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKBcXQF4FOtG",
        "colab_type": "text"
      },
      "source": [
        " Average word length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vThmaSWUEs9Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['avewordlength']=train['charcount']/train['wordcount']\n",
        "test['avewordlength']=test['charcount']/test['wordcount']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5A3R5ec4FbHF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEqrKXjDFTxI",
        "colab_type": "text"
      },
      "source": [
        "Contractions to Expansions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePm6xhvLFolp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean(text):\n",
        "    text = re.sub(\" he's \", \" he is \", text)\n",
        "    text = re.sub(\" there's \", \" there is \", text)\n",
        "    text = re.sub(\" we're \", \" we are \", text)\n",
        "    text = re.sub(\"you'll\", \" you will \", text)\n",
        "\n",
        "    text = re.sub(\" that's \", \" that is \", text)\n",
        "    text = re.sub(\" won't \", \" will not \", text)\n",
        "    text = re.sub(\" they're \", \" they are \", text)\n",
        "    text = re.sub(\" wan't \", \" cannot \", text)\n",
        "    text = re.sub(\" wasn't \", \" was not \", text)\n",
        "    text = re.sub(\" aren't \", \" are not \", text)\n",
        "    text = re.sub(\" isn't \", \" is not \", text)\n",
        "    text = re.sub(\"haven't\", \" have not \", text)\n",
        "    text = re.sub(\" hasn't \", \" has not \", text)\n",
        "    text = re.sub(\" there's \", \" there is \", text)\n",
        "    text = re.sub(\" he's \", \" he is \", text)\n",
        "    text = re.sub(\" it's \", \" it is \", text)\n",
        "    text = re.sub(\" wou're \", \" you are \", text)\n",
        "    text = re.sub(\" isnt \", \" is not \", text)\n",
        "    text = re.sub(\" shouldn't \", \" should not \", text)\n",
        "    text = re.sub(\" wouldn't \", \" would not \", text)\n",
        "    text = re.sub(\"i'm\", \" i am \", text)\n",
        "    text = re.sub(\"i'm \", \" i am \", text)\n",
        "    text = re.sub(\" im \", \" i am \", text)\n",
        "    text = re.sub(\" youre \", \" you are \", text)\n",
        "    text = re.sub(\" ive \", \" i have \", text)\n",
        "    text = re.sub(\" cant \", \" can not \", text)\n",
        "    text = re.sub(\" ive \", \" i have \", text)\n",
        "    text = re.sub(\" dont \", \" do not \", text)\n",
        "    text = re.sub(\"doesnt\", \" does not \", text)\n",
        "    text = re.sub(\" thats \", \" that is \", text)\n",
        "    text = re.sub(\" doesnt \", \" does not \", text)\n",
        "    text = re.sub(\" don ‘ t \", \" do not \", text) \n",
        "    text = re.sub(\" i'll\", \" i will \", text)\n",
        "\n",
        "    text = re.sub(\" isn't \", \" is not \", text)\n",
        "    text = re.sub(\" here's\", \" here is \", text)\n",
        "    text = re.sub(\" you've\", \" you have \", text)\n",
        "    text = re.sub(\" we're\", \" we are \", text)\n",
        "    text = re.sub(\" what's\", \" what is \", text)\n",
        "    text = re.sub(\" couldn't\", \"could not\", text)\n",
        "    text = re.sub(\" we've\", \" we have \", text)\n",
        "    text = re.sub(\" who's\", \" who is \", text)\n",
        "    text = re.sub(\" y'all\", \" you all \", text)\n",
        "    text = re.sub(\" would've\", \" would have \", text)\n",
        "    text = re.sub(\" it'll\", \" it will \", text)\n",
        "    text = re.sub(\" we'll\", \" we will \", text)\n",
        "    text = re.sub(\" we've\", \" we have \", text)\n",
        "    text = re.sub(\" he'll\", \" he will \", text)\n",
        "    text = re.sub(\" y'all\", \" you all \", text)\n",
        "    text = re.sub(\" weren't\", \" were not \", text)\n",
        "    text = re.sub(\" didn't\", \" did not \", text)\n",
        "    text = re.sub(\" they'll\", \" they will \", text)\n",
        "    text = re.sub(\" they'd\", \" they would \", text)\n",
        "    text = re.sub(\" they've\", \" they have \", text)\n",
        "    text = re.sub(\" i'd\", \" i would \", text)\n",
        "    text = re.sub(\" should've\", \" should have \", text)\n",
        "    text = re.sub(\" where's\", \" where is \", text)\n",
        "    text = re.sub(\" we'd\", \" we would \", text)\n",
        "    text = re.sub(\" weren't\", \" were not \", text)\n",
        "    text = re.sub(\" they're\", \" they are \", text)\n",
        "    text = re.sub(\" let's\", \" let us \", text)\n",
        "    text = re.sub(\" it's\", \" it is \", text)\n",
        "    text = re.sub(\" can't\", \" cannot \", text)\n",
        "    text = re.sub(\" don't\", \" do not \", text)\n",
        "    text = re.sub(\" you're\", \" you are \", text)\n",
        "    text = re.sub(\" i've\", \" i have \", text)\n",
        "    text = re.sub(\" that's\", \" that is \", text)\n",
        "    text = re.sub(\" doesn't\", \" does not \", text)\n",
        "    text = re.sub(\" i'd\", \" i would \", text)\n",
        "    text = re.sub(\" didn't\", \" did not \", text)\n",
        "    text = re.sub(\" ain't\", \" am not \", text)\n",
        "    text = re.sub(\" you'll\", \" you will \", text)\n",
        "    text = re.sub(\" i've\", \" i have \", text)\n",
        "    text = re.sub(\" don't\", \" do not \", text)\n",
        "    text = re.sub(\"i'll\", \" i will \", text)\n",
        "    text = re.sub(\" i'd\", \" i would \", text)\n",
        "    text = re.sub(\" let's\", \" let us \", text)\n",
        "    text = re.sub(\" you'd\", \" you would \", text)\n",
        "    text = re.sub(\" it's\", \" it is \", text)\n",
        "    text = re.sub(\" ain't\", \" am not \", text)\n",
        "    text = re.sub(\" could've\", \" could have \", text)\n",
        "    text = re.sub(\"youve\", \" you have \", text)  \n",
        "    text = re.sub(\"i'm\", \" i am \", text)   \n",
        "\n",
        "            \n",
        "#     Character entity references\n",
        "    text = re.sub(\"&gt;\", \">\", text)\n",
        "    text = re.sub(\"&lt;\", \"<\", text)\n",
        "    text = re.sub(\"&amp;\", \"&\", text)\n",
        "    return text\n",
        "  \n",
        "\n",
        "train['text'] = train['text'].apply(lambda x: clean(x))\n",
        "test['text'] = test['text'].apply(lambda x: clean(x))\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T4nH6wHF7n1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4haLwsIFYZQ",
        "colab_type": "text"
      },
      "source": [
        "Printing Stopwords in SpaCy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofAmsq1VF9TY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " print(stopwords)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTGiG7y9G0Rc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " len(stopwords)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGjYDB_lFdN0",
        "colab_type": "text"
      },
      "source": [
        "Number of stopword in a tweet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxB5CmfOiT6W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stopwordcount(text):\n",
        "  stpwrd=[]\n",
        "  x=text.split()\n",
        "  for t in x:\n",
        "    if t in stopwords:\n",
        "      stpwrd.append(t)\n",
        "  return len(stpwrd)\n",
        "      \n",
        "      \n",
        "train['number of stop words']=train['text'].apply(lambda x: stopwordcount(x))\n",
        "test['number of stop words']=test['text'].apply(lambda x: stopwordcount(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFV4ncOpjF3v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPP-juAijeg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# number of hashtags and mentions \n",
        "# [t for t in x.split() if t.startswith('#') ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0QzZU6VFj0J",
        "colab_type": "text"
      },
      "source": [
        "Number of digits in a tweet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFm__pPCnBWE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# number of digits\n",
        "train['text'].apply(lambda x: len([ t for t in x.split() if t.isdigit()]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NA5--J1IFs-Y",
        "colab_type": "text"
      },
      "source": [
        "Number of upper case words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bd6BJM5unnAS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Upper case count\n",
        "# Since upper case words have higher intensity while telling a word\n",
        "train['uppercount']=train['text'].apply(lambda x: len([t for t in x.split() if t.isupper()]))\n",
        "test['uppercount']=test['text'].apply(lambda x: len([t for t in x.split() if t.isupper()]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdUzFHR8pAly",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.sample(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk-2cHiZpMEC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # lower case conversion\n",
        " train['text']=train['text'].apply(lambda x:str(x).lower())\n",
        " test['text']=test['text'].apply(lambda x:str(x).lower())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zyg7pi-usmx2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove Accented Chars\n",
        "import unicodedata\n",
        "def remove_accented_chars(x):\n",
        "  x=unicodedata.normalize('NFKD',x).encode('ascii','ignore').decode('utf-8','ignore')\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdIUZ399vkZg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['text']=train['text'].apply(lambda x: remove_accented_chars(x))\n",
        "test['text']=test['text'].apply(lambda x: remove_accented_chars(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxNe9avXvyDs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove stopwords\n",
        "def remove_stopwords(text):\n",
        "  s=[]\n",
        "  x=text.split()\n",
        "  for t in x:\n",
        "    if t not in stopwords:\n",
        "      s.append(t)\n",
        "  return s\n",
        "train['text_no_stopword']=train['text'].apply(lambda x :' '.join([t for t in x.split() if t not in stopwords]))\n",
        "test['text_no_stopword']=test['text'].apply(lambda x :' '.join([t for t in x.split() if t not in stopwords]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HE6CGuR0wXH7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeJ5XbP6GDOY",
        "colab_type": "text"
      },
      "source": [
        "Lemmetization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrT7LmatwrAT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lemmetization\n",
        "nlp=spacy.load('en')\n",
        "def make_to_base(text):\n",
        "  x=str(text)\n",
        "  x_list=[]\n",
        "  doc=nlp(x)\n",
        "\n",
        "  for token in doc:\n",
        "    lemma=token.lemma_\n",
        "    if lemma =='-PRON-' or lemma =='be':\n",
        "      lemma=token.text\n",
        "\n",
        "    x_list.append(lemma)\n",
        "  return ' '.join(x_list)\n",
        "\n",
        "train['text']=train['text'].apply(lambda x:make_to_base(x))\n",
        "test['text']=test['text'].apply(lambda x:make_to_base(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0XlmqE7zGOI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# common words removal\n",
        "text=' '.join(train['text'])\n",
        "len(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucqlptdp2anx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "text=text.split()\n",
        "len(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RNNsatK2owT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "freq=pd.Series(text).value_counts()[:20]\n",
        "sns.barplot(freq.index,freq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hQcujZy2zFQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Finding Rare Words\n",
        "freq=pd.Series(text).value_counts()\n",
        "freq.tail(5000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "930LxVk84qD_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from wordcloud import WordCloud\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiQaGLgd6WBk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text=' '.join(train['text_no_stopword'])\n",
        "wc=WordCloud(width=800,height=400).generate(text)\n",
        "plt.imshow(wc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8S77uTqf6ltQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text=' '.join(test['text_no_stopword'])\n",
        "wc=WordCloud(width=800,height=400).generate(text)\n",
        "plt.imshow(wc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tslHWnAm67vt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ah8eeOy78FFV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ngram analysis\n",
        "def get_top_tweet_bigrams(corpus, n=None):\n",
        "    vec = CountVectorizer(ngram_range=(2, 2)).fit(corpus)\n",
        "    bag_of_words = vec.transform(corpus)\n",
        "    sum_words = bag_of_words.sum(axis=0) \n",
        "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
        "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
        "    return words_freq[:n]\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "top_tweet_bigrams=get_top_tweet_bigrams(train['text'])[:10]\n",
        "x,y=map(list,zip(*top_tweet_bigrams))\n",
        "sns.barplot(x=y,y=x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9gVenn28ML3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ngram analysis\n",
        "def get_top_tweet_bigrams(corpus, n=None):\n",
        "    vec = CountVectorizer(ngram_range=(3, 3)).fit(corpus)\n",
        "    bag_of_words = vec.transform(corpus)\n",
        "    sum_words = bag_of_words.sum(axis=0) \n",
        "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
        "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
        "    return words_freq[:n]\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "top_tweet_bigrams=get_top_tweet_bigrams(train['text'])[:20]\n",
        "x,y=map(list,zip(*top_tweet_bigrams))\n",
        "sns.barplot(x=y,y=x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uBXjNxF8RN5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWSr2jJL8Y4o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "25/7613\n",
        "#not great tri-gram"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_4YvQ5RHlJ1",
        "colab_type": "text"
      },
      "source": [
        "BERT Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1swwyzd8bNJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Al0RZxa8u5l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfS6rivk8oNV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import ktrain\n",
        "from ktrain import text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpZAGXdE8rLm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(train['text'].values,train['target'].values, test_size = 0.2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIlgZUGw2mtC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train=pd.DataFrame(x_train,columns=['text'])\n",
        "x_valid=pd.DataFrame(x_valid,columns=['text'])\n",
        "y_train=pd.DataFrame(y_train,columns=['target'])\n",
        "y_valid=pd.DataFrame(y_valid,columns=['target'])\n",
        "\n",
        "Train=pd.concat([x_train,y_train],1)\n",
        "Test=pd.concat([x_valid,y_valid],1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76YTyDyx3mEe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-4tFlkV1ibm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train,y_train),(x_test,y_test),preprocess=text.texts_from_df(train_df=Train,text_column='text',label_columns='target',val_df=Test,maxlen=130,preprocess_mode='bert')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCRdujvY1imE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-xrcTRV1irj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=text.text_classifier(name='bert',train_data=(x_train,y_train),preproc=preprocess)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSO4XG851i2F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner=ktrain.get_learner(model=model,train_data=(x_train,y_train),val_data=(x_test,y_test),batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ro-F6JKD1i8r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#learner.lr_find()\n",
        "#learner.lr_plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6KXFynX1jAx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.fit_onecycle(lr=1e-5,epochs=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6tJSu8n1i7j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " predictor=ktrain.get_predictor(learner.model,preproc=preprocess)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FF1ZAz6N_vuq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8e9Bo4_L1izk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "d=np.array(test['text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCHXmroR1ivy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred=predictor.predict(d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7VzsYbLBFEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGbKEW0K1iph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred=pd.DataFrame(y_pred,columns=['target'])\n",
        "id=pd.DataFrame(test['id'],columns=['id'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6U-ONYm1iji",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final=pd.concat([id,y_pred],1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bg7UJDz-1ihM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvV_nC_E1ieo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final.to_csv(\"kaggle.csv\")\n",
        "from google.colab import files\n",
        "files.download('kaggle.csv') \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JE7WP1cq1iZc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEmlmrMlB1uB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19lPtvh_B1zd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3e5iZFOtB17S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-l-gtXyB1-a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7-wfE3FB2IR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PZc2ySzB2SZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ft7v6qjB2Mg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2LoJOt7B2Gp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAHvOMJXB2EI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yy5zNuQiB2Cq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OddosyJQB15y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KbTMv2RB13a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90xh0OyzB1xh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwhlIMuR-c2r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p46VS8aX-Zx1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=train.drop(['target'],1)\n",
        "y=train['target']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sy7HqMM-l6f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL_NAME = 'distilbert_base_uncased'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bt4dTnAzLLK9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install -q tensorflow_gpu==2.1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6E1dAuxPXhF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL_NAME = 'distilbert-base-uncased'\n",
        "t = text.Transformer(MODEL_NAME, maxlen=75, class_names = [0, 1])\n",
        "trn = t.preprocess_train(x_train, y_train)\n",
        "val = t.preprocess_test(x_valid, y_valid)\n",
        "model = t.get_classifier()\n",
        "learner = ktrain.get_learner(model, train_data=trn, val_data=val, batch_size=600)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01tvH9aLQspb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.fit_onecycle(0.5, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLIFjf_APCHM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = text.text_classifier('bert', (x_train, y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jppRkADs-p-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = text.Transformer(MODEL_NAME, maxlen = 220, class_names = [0, 1])\n",
        "trn = t.preprocess_train(x_train, y_train)\n",
        "val = t.preprocess_train(x_valid, y_valid)\n",
        "model = t.get_classifier()\n",
        "\n",
        "#learner = ktrain.get_learner(model, train_data = trn, val_data = val, batch_size = 8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVRgiQUv-tml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}